---
layout: page
title: Home
nav_bar: True
---

<div>
<p>
<img src="/assets/profile-picture.jpg" alt="me" style="width:  50%; margin-left: 25%; margin-right: 25%; ">
</p>
</div>

I'm Robert Kirk, a PhD Student at [UCL DARK Lab](https://ucl-dark.github.io/) in the [UCL Centre for Artificial Intelligence](https://www.ucl.ac.uk/ai-centre/) supervised by [Tim Rockt√§schel](https://rockt.github.io/) and [Edward Grefenstette](https://www.egrefen.com/). I'm an aspiring <a href="https://www.effectivealtruism.org/">effective altruist</a> and rationalist. I'm interested in generalisation in reinforcement learning, out-of-distribution robustness, and AI safety and alignment.

Before that, I worked for <a href="https://smarkets.com/careers/">Smarkets</a>, a sports and politics betting exchange, as an infrastructure and software engineer for two years. For the first year and a half I worked as a software engineering in a team developing python micro-services, and then I moved to join the infrastructure team.

Before that I studied for four years at [Somerville college](https://www.some.ox.ac.uk/), University of Oxford, for an integrated masters in mathematics and computer science. Up until the fourth year I maintained a 50/50 split between the two subjects, and in the fourth year I focused more on abstract computer science. I did my [masters thesis](https://github.com/RobertKirk/Graph-Comonads-from-Pebble-Games) on implementing the comonadic formulation of pebble games in [Idris](https://www.idris-lang.org/) supervised by [Samson Abramsky](http://www.cs.ox.ac.uk/people/samson.abramsky/).

I used to write for the [Alignment Newsletter](https://rohinshah.com/alignment-newsletter/), mostly on the topics of interpretability and reinforcement learning. Originally formed as part of [AI Safety Research Program](https://aisrp.org/), I've collaborated with a small group of fellow independent researchers on interpretability, both doing technical research and thinking about how interpretability helps AI alignment, the results of which can be seen [here](/tag/aisrp).

Other than technical things, I'm interested in rationality, neuroscience, cooking, videogames, music (basically any genre), and reading. I sing in a choir and previously played the French horn.

This site is a place where I'll share my thoughts on all of these topics and possibly more, but the content will mostly be technical AI and AI safety related.
